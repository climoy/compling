{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import punctuation\n",
    "from razdel import sentenize\n",
    "from razdel import tokenize as razdel_tokenize\n",
    "import numpy as np\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "dvach = open('2ch_corpus.txt', encoding='utf-8').read()[:50000]\n",
    "lenta = open('lenta.txt', encoding='utf-8').read()[:50000]\n",
    "\n",
    "\n",
    "def normalize(text):\n",
    "    normalized_text = [word.text.strip(punctuation) for word \\\n",
    "                                                            in razdel_tokenize(text)]\n",
    "    normalized_text = [word.lower() for word in normalized_text if word and len(word) < 20 ]\n",
    "    return normalized_text\n",
    "\n",
    "\n",
    "def ngrammer(tokens, n=2):\n",
    "    ngrams = []\n",
    "    for i in range(0,len(tokens)-n+1):\n",
    "        ngrams.append(' '.join(tokens[i:i+n]))\n",
    "    return ngrams\n",
    "\n",
    "\n",
    "def generate(matrix, id2word, bigram2id, n=100, start='<start> <start>'):\n",
    "    text = []\n",
    "    current_idx = bigram2id[start]\n",
    "    current_bigram = start\n",
    "    for i in range(n):\n",
    "        chosenindex = np.random.choice(matrix.shape[1], p=matrix[current_idx])\n",
    "        appended = id2word[chosenindex]\n",
    "        text.append(appended)\n",
    "        if appended == '<end>':\n",
    "            current_idx = bigram2id['<start> <start>']\n",
    "            current_bigram = '<start> <start>'\n",
    "            continue\n",
    "        current_bigram = current_bigram.split()[1]+' '+appended\n",
    "        current_idx = bigram2id[current_bigram]\n",
    "    return ' '.join(text)\n",
    "\n",
    "\n",
    "\n",
    "sentences_dvach = [['<start>']+['<start>'] + normalize(text) + ['<end>'] for text in sent_tokenize(dvach)]\n",
    "#\n",
    "sentences_lenta = [['<start>']+['<start>'] + normalize(text) + ['<end>'] for text in sent_tokenize(lenta)]\n",
    "\n",
    "\n",
    "unigrams_dvach = Counter()\n",
    "bigrams_dvach = Counter()\n",
    "trigrams_dvach = Counter()\n",
    "#\n",
    "unigrams_lenta = Counter()\n",
    "bigrams_lenta = Counter()\n",
    "trigrams_lenta = Counter()\n",
    "\n",
    "\n",
    "for sentence in sentences_dvach:\n",
    "    unigrams_dvach.update(sentence)\n",
    "    bigrams_dvach.update(ngrammer(sentence))\n",
    "    trigrams_dvach.update(ngrammer(sentence, n=3))\n",
    "#\n",
    "for sentence in sentences_lenta:\n",
    "    unigrams_lenta.update(sentence)\n",
    "    bigrams_lenta.update(ngrammer(sentence))\n",
    "    trigrams_lenta.update(ngrammer(sentence, n=3))\n",
    "    \n",
    "\n",
    "matrix_dvach = np.zeros((len(bigrams_dvach), \n",
    "                   len(unigrams_dvach)))\n",
    "id2word_dvach = list(unigrams_dvach)\n",
    "word2id_dvach = {word:i for i, word in enumerate(id2word_dvach)}\n",
    "id2bigram_dvach = list(bigrams_dvach)\n",
    "bigram2id_dvach = {word:i for i, word in enumerate(id2bigram_dvach)}\n",
    "#\n",
    "matrix_lenta = np.zeros((len(bigrams_lenta), \n",
    "                   len(unigrams_lenta)))\n",
    "id2word_lenta = list(unigrams_lenta)\n",
    "word2id_lenta = {word:i for i, word in enumerate(id2word_lenta)}\n",
    "id2bigram_lenta = list(bigrams_lenta)\n",
    "bigram2id_lenta = {word:i for i, word in enumerate(id2bigram_lenta)}\n",
    "\n",
    "\n",
    "for ngram in trigrams_dvach:\n",
    "    word1, word2, word3 = ngram.split()\n",
    "    matrix_dvach[bigram2id_dvach[word1+' '+word2]][word2id_dvach[word3]] =  (trigrams_dvach[ngram]/\n",
    "                                                                             bigrams_dvach[word1+' '+word2])\n",
    "#\n",
    "for ngram in trigrams_lenta:\n",
    "    word1, word2, word3 = ngram.split()\n",
    "    matrix_lenta[bigram2id_lenta[word1+' '+word2]][word2id_lenta[word3]] =  (trigrams_lenta[ngram]/\n",
    "                                                                             bigrams_lenta[word1+' '+word2])\n",
    "    \n",
    "    \n",
    "dvachfashion = generate(matrix_dvach, id2word_dvach, bigram2id_dvach).replace('<end>', '\\n')\n",
    "lentafashion = generate(matrix_lenta, id2word_lenta, bigram2id_lenta).replace('<end>', '\\n')\n",
    "\n",
    "with open('results.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write(dvachfashion)\n",
    "    f.write('\\n\\n')\n",
    "    f.write(lentafashion)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
